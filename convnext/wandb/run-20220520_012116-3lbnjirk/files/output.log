
Epoch [1/40]:   1%|█▊                                                                                                                      | 2/134 [00:00<01:01,  2.16it/s, loss=4.68]
CattleNet(
  (convnext_tiny): Sequential(
    (0): ConvNeXt(
      (features): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)
        )
        (1): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)
          )
        )
        (2): Sequential(
          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
        )
        (3): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)
          )
        )
        (4): Sequential(
          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
        )
        (5): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)
          )
          (3): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)
          )
          (4): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)
          )
          (5): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)
          )
          (6): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)
          )
          (7): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)
          )
          (8): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)
          )
        )
        (6): Sequential(
          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
        )
        (7): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.1, mode=row)
          )
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (classifier): Sequential(
        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)
        (1): Flatten(start_dim=1, end_dim=-1)
        (2): Linear(in_features=768, out_features=4096, bias=True)
      )
    )
    (1): Sigmoid()
  )
)

























Epoch [1/40]:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 132/134 [00:51<00:00,  2.57it/s, loss=0.218]
lr 0.001
Epoch 1

 Current loss 1.4557443577083828
Accuracy: 0.24615384615384617


























Epoch [2/40]:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 129/134 [00:53<00:02,  2.34it/s, loss=0.275]
lr 0.001
Epoch 2

 Current loss 0.3408522649265047
Accuracy: 0.3412698412698413


























Epoch [3/40]:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 132/134 [00:54<00:00,  2.41it/s, loss=0.246]
lr 0.001
Epoch 3

 Current loss 0.29208724867941727
Accuracy: 0.3560606060606061



























Epoch [4/40]:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 132/134 [00:54<00:00,  2.28it/s, loss=0.244]
lr 0.001
Epoch 4

 Current loss 0.28005965799093246
Accuracy: 0.2890625


























Epoch [5/40]:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 131/134 [00:52<00:01,  2.42it/s, loss=0.293]
lr 0.001
Epoch 5

 Current loss 0.2734283212183127
Accuracy: 0.28


























Epoch [6/40]:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 130/134 [00:52<00:01,  2.47it/s, loss=0.275]
lr 0.001
Epoch 6

 Current loss 0.2687126518185459
Accuracy: 0.2894736842105263

























Epoch [7/40]:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 131/134 [00:50<00:01,  2.53it/s, loss=0.257]
lr 0.001
Epoch 7

 Current loss 0.273488635781096
  0%|                                                                                                                                                         | 0/134 [00:00<?, ?it/s]


























Epoch [8/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 128/134 [00:49<00:02,  2.49it/s, loss=0.268]
lr 0.001
Epoch 8
 Current loss 0.26966602355241776
Accuracy: 0.2945205479452055

























Epoch [9/40]:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 131/134 [00:51<00:01,  2.57it/s, loss=0.274]
lr 0.001
Epoch 9

 Current loss 0.26890510809955315
  0%|                                                                                                                                                         | 0/134 [00:00<?, ?it/s]


























Epoch [10/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 129/134 [00:51<00:02,  2.40it/s, loss=0.258]
lr 0.0001
Epoch 10

 Current loss 0.26834466363956677
Accuracy: 0.2708333333333333

























Epoch [11/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 129/134 [00:51<00:01,  2.54it/s, loss=0.257]
lr 0.0001
Epoch 11

 Current loss 0.2621016521284829
Accuracy: 0.40625

























Epoch [12/40]:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 133/134 [00:51<00:00,  2.60it/s, loss=0.256]
lr 0.0001
Epoch 12

 Current loss 0.2634356829212673
Accuracy: 0.25

























Epoch [13/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 129/134 [00:49<00:01,  2.68it/s, loss=0.254]
lr 0.0001
Epoch 13
 Current loss 0.2617093714982716
Epoch [14/40]:   0%|                                                                                                                                          | 0/134 [00:00<?, ?it/s]

























Epoch [14/40]:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 130/134 [00:50<00:01,  2.70it/s, loss=0.275]
lr 0.0001
Epoch 14
Traceback (most recent call last):
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/setup.py", line 155, in <module>
    model = train()
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/setup.py", line 131, in train
    acc = test(test_dataset,model=model,is_load_model=False)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/model_test.py", line 85, in test
    data_dict = encode_dataset(test_dataset, model_directory, model_version,model,is_load_model)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/model_test.py", line 51, in encode_dataset
    out1,out2 = model(imgs1,imgs2)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/cattleNetTest.py", line 50, in forward
    out1 = self.forward_once(input1)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/cattleNetTest.py", line 44, in forward_once
    x = self.convnext_tiny(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 186, in forward
    return self._forward_impl(x)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 180, in _forward_impl
    x = self.features(x)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 73, in forward
    result = self.layer_scale * self.block(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 670, in forward
    return F.gelu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 5.80 GiB total capacity; 2.85 GiB already allocated; 40.44 MiB free; 2.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF