
Epoch [1/40]:   1%|█▊                                                                                                                         | 4/267 [00:00<00:51,  5.08it/s, loss=0]
CattleNet(
  (convnext_tiny): Sequential(
    (0): ConvNeXt(
      (features): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)
        )
        (1): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
              (1): Permute()
              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=96, out_features=384, bias=True)
              (4): GELU()
              (5): Linear(in_features=384, out_features=96, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)
          )
        )
        (2): Sequential(
          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
        )
        (3): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
              (1): Permute()
              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=192, out_features=768, bias=True)
              (4): GELU()
              (5): Linear(in_features=768, out_features=192, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)
          )
        )
        (4): Sequential(
          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
        )
        (5): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)
          )
          (3): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)
          )
          (4): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)
          )
          (5): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)
          )
          (6): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)
          )
          (7): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)
          )
          (8): CNBlock(
            (block): Sequential(
              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
              (1): Permute()
              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=384, out_features=1536, bias=True)
              (4): GELU()
              (5): Linear(in_features=1536, out_features=384, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)
          )
        )
        (6): Sequential(
          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
        )
        (7): Sequential(
          (0): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)
          )
          (1): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)
          )
          (2): CNBlock(
            (block): Sequential(
              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
              (1): Permute()
              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
              (3): Linear(in_features=768, out_features=3072, bias=True)
              (4): GELU()
              (5): Linear(in_features=3072, out_features=768, bias=True)
              (6): Permute()
            )
            (stochastic_depth): StochasticDepth(p=0.1, mode=row)
          )
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (classifier): Sequential(
        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)
        (1): Flatten(start_dim=1, end_dim=-1)
        (2): Linear(in_features=768, out_features=4096, bias=True)
      )
    )
    (1): Sigmoid()
  )
)

























Epoch [1/40]:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 257/267 [00:51<00:02,  4.63it/s, loss=0.396]
lr 0.001
Epoch 1

 Current loss 1.071627310854784
Accuracy: 0.325

























Epoch [2/40]:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 258/267 [00:51<00:01,  5.15it/s, loss=0.271]
lr 0.001
Epoch 2

 Current loss 0.2855282420857569
Accuracy: 0.2835820895522388


























Epoch [3/40]:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 257/267 [00:51<00:01,  5.10it/s, loss=0.278]
lr 0.001
Epoch 3
 Current loss 0.2707426325602924
Accuracy: 0.35714285714285715


























Epoch [4/40]:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 265/267 [00:52<00:00,  4.84it/s, loss=0.338]
lr 0.001
Epoch 4

 Current loss 0.2694870482167501
Accuracy: 0.25862068965517243


























Epoch [5/40]:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 257/267 [00:52<00:01,  5.11it/s, loss=0.218]
lr 0.001
Epoch 5

 Current loss 0.26272017715240686
Accuracy: 0.3076923076923077

























Epoch [6/40]:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 259/267 [00:51<00:01,  5.29it/s, loss=0.255]
lr 0.001
Epoch 6

 Current loss 0.2730459928066096
Accuracy: 0.3359375

























Epoch [7/40]:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 264/267 [00:51<00:00,  5.30it/s, loss=0.26]
lr 0.001
Epoch 7

 Current loss 0.26879195188091937
Epoch [8/40]:   0%|▍                                                                                                                      | 1/267 [00:00<01:02,  4.23it/s, loss=0.321]


























Epoch [8/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 257/267 [00:50<00:02,  4.97it/s, loss=0.0789]
lr 0.001
Epoch 8
 Current loss 0.272743635716733
Accuracy: 0.36538461538461536


























Epoch [9/40]:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 259/267 [00:51<00:01,  5.22it/s, loss=0.282]
lr 0.001
Epoch 9
 Current loss 0.2712053529611241
Accuracy: 0.31343283582089554


























Epoch [10/40]:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 256/267 [00:50<00:02,  5.35it/s, loss=0.259]
lr 0.0001
Epoch 10
 Current loss 0.26913595157727765
Accuracy: 0.43478260869565216


























Epoch [11/40]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 266/267 [00:52<00:00,  4.82it/s, loss=0.198]
lr 0.0001
Epoch 11

 Current loss 0.2654053277793002
Accuracy: 0.33098591549295775

























Traceback (most recent call last):
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/setup.py", line 155, in <module>
    model = train()
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/setup.py", line 131, in train
    acc = test(test_dataset,model=model,is_load_model=False)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/model_test.py", line 85, in test
    data_dict = encode_dataset(test_dataset, model_directory, model_version,model,is_load_model)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/model_test.py", line 51, in encode_dataset
    out1,out2 = model(imgs1,imgs2)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/cattleNetTest.py", line 51, in forward
    out2 = self.forward_once(input2)
  File "/home/adriansegura/Desktop/RUG/CattleNet/convnext/cattleNetTest.py", line 44, in forward_once
    x = self.convnext_tiny(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 186, in forward
    return self._forward_impl(x)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 180, in _forward_impl
    x = self.features(x)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torchvision/models/convnext.py", line 73, in forward
    result = self.layer_scale * self.block(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/adriansegura/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 5.80 GiB total capacity; 2.95 GiB already allocated; 32.81 MiB free; 3.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
lr 0.0001
Epoch 12
 Current loss 0.2600919423478373